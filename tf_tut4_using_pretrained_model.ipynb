{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d78197-b6ba-4139-bb63-2f75db8141b3",
   "metadata": {},
   "source": [
    "## Using Pretrained Models\n",
    "TensorFlow provides a wide range of pretrained models in tf.keras.applications. These models are pre-trained on large datasets (like ImageNet) and can be used directly for transfer learning.\n",
    "\n",
    "The VGG16 model you loaded was initialized without the top classification layers (include_top=False), which means it does not provide predictions in terms of human-readable class labels (like \"elephant\" or \"dog\"). Instead, it outputs feature maps from the convolutional layers.\n",
    "\n",
    "Example (Using a Pretrained Model for Image Classification): (Took 17 seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0398fd-c07e-4774-9fdc-bfe19e28de4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675ms/step\n",
      "Predictions: [[[[-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         19.05331    ... -0.         -0.\n",
      "    -0.        ]\n",
      "   ...\n",
      "   [-0.         -0.         38.652523   ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.          7.3346276  ... -0.          2.0215232\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.          4.0603657\n",
      "    -0.        ]]\n",
      "\n",
      "  [[-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [ 2.7255654  -0.         22.054188   ... -0.         -0.\n",
      "    18.784767  ]\n",
      "   ...\n",
      "   [26.836723   -0.         44.098248   ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         28.540737   ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "     0.46292737]]\n",
      "\n",
      "  [[-0.         -0.         -0.         ... -0.          1.4470661\n",
      "    -0.        ]\n",
      "   [-0.         -0.          2.9581008  ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.          4.131012   ... -0.         -0.\n",
      "    16.213247  ]\n",
      "   ...\n",
      "   [35.149517   -0.         -0.         ... 47.23402    -0.\n",
      "    18.974838  ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "     5.774252  ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "     5.5787373 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   ...\n",
      "   [-0.         -0.         10.079561   ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]]\n",
      "\n",
      "  [[-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... 12.396514   -0.\n",
      "    -0.        ]\n",
      "   ...\n",
      "   [-0.         -0.         23.561779   ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.          5.734057   ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]]\n",
      "\n",
      "  [[-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   ...\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]\n",
      "   [-0.         -0.         -0.         ... -0.         -0.\n",
      "    -0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load a pretrained VGG16 model (without top layers)\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "# Load an image\n",
    "img_path = 'elephant.jpg'  # Change this to a valid image file path\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# Preprocess the image for VGG16\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(img_array)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642d76e6-4b4f-4c1a-9ac1-773aa3053b4d",
   "metadata": {},
   "source": [
    "# Covert above output to Human readable form\n",
    "The VGG16 model you loaded was initialized without the top classification layers (include_top=False), which means it does not provide predictions in terms of human-readable class labels (like \"elephant\" or \"dog\"). Instead, it outputs feature maps from the convolutional layers.\n",
    "\n",
    "To get predictions as human-readable class labels, you need to use the full VGG16 model with the top layers included. Here's how you can do that:(Took 3 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ace273c6-36e6-477b-a8c6-4d224cf6ba26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m553467096/553467096\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 0us/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686ms/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Predictions (Top 3):\n",
      "1: tusker (0.49)\n",
      "2: African_elephant (0.45)\n",
      "3: Indian_elephant (0.06)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load a pretrained VGG16 model (with top layers)\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "# Load an image\n",
    "img_path = 'elephant.jpg'  # Change this to a valid image file path\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "# Preprocess the image for VGG16\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = tf.keras.applications.vgg16.preprocess_input(img_array)\n",
    "\n",
    "# Get model predictions\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# Decode the predictions into human-readable labels\n",
    "decoded_predictions = decode_predictions(predictions, top=3)  # Get top 3 predictions\n",
    "print(\"Predictions (Top 3):\")\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_predictions[0]):\n",
    "    print(f\"{i + 1}: {label} ({score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e2a6f1-7f04-4769-8a7a-6eafa9923b2d",
   "metadata": {},
   "source": [
    "## TensorFlow Datasets (tf.data)\n",
    "tf.data provides utilities to efficiently load and preprocess datasets, especially when working with large datasets.\n",
    "\n",
    "Example (Creating a Dataset using tf.data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007cd531-8d1e-4920-850a-754f477fed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a simple dataset of numbers\n",
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5])\n",
    "\n",
    "# Map a function to each element in the dataset\n",
    "dataset = dataset.map(lambda x: x * 2)\n",
    "\n",
    "# Print out each element in the dataset\n",
    "for element in dataset:\n",
    "    print(element.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bbf611-6f5c-4ee4-94e8-f9ddd2510adb",
   "metadata": {},
   "source": [
    "## Custom Training Loop\n",
    "For more complex training routines (e.g., for reinforcement learning or certain custom optimizers), you can write your own training loop using GradientTape.\n",
    "\n",
    "Example (Custom Training Loop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107f7bcb-1aad-4b2d-9c86-4e245a7b400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hi\\Desktop\\projects\\python_projects\\ai_projects\\GenAI_GAN1\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss = 1.5951018333435059\n",
      "Step 10: Loss = 6.633349418640137\n",
      "Step 20: Loss = 6.609179496765137\n",
      "Step 30: Loss = 3.948230743408203\n",
      "Step 40: Loss = 5.828388214111328\n",
      "Step 50: Loss = 6.446093559265137\n",
      "Step 60: Loss = 3.0485167503356934\n",
      "Step 70: Loss = 9.481471061706543\n",
      "Step 80: Loss = 4.795212745666504\n",
      "Step 90: Loss = 7.722182273864746\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
    "])\n",
    "\n",
    "# Define a loss function and optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Custom training loop\n",
    "for step in range(100):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass\n",
    "        x = tf.random.normal([10, 1])  # Random input data\n",
    "        y = 2 * x + 1  # Ground truth labels\n",
    "        y_pred = model(x)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = loss_fn(y, y_pred)\n",
    "    \n",
    "    # Compute gradients and apply them\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    if step % 10 == 0:\n",
    "        print(f\"Step {step}: Loss = {loss.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5adab44-83fc-4648-a65e-03f5b03d2c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
